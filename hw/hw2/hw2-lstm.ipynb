{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": "# Read and prepare for the data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# some global import\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport numpy as np\nimport os\n\nimport tqdm",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-24T02:51:31.790741Z",
     "iopub.execute_input": "2022-11-24T02:51:31.791228Z",
     "iopub.status.idle": "2022-11-24T02:51:32.488581Z",
     "shell.execute_reply.started": "2022-11-24T02:51:31.791192Z",
     "shell.execute_reply": "2022-11-24T02:51:32.487086Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# some global variables\ntrain_data_path = '../input/ml2021spring-hw2/timit_11/timit_11/train_11.npy'\ntrain_label_path = '../input/ml2021spring-hw2/timit_11/timit_11/train_label_11.npy'\ntest_data_path = '../input/ml2021spring-hw2/timit_11/timit_11/test_11.npy'\n\nbatch_size = 2048\nlr = 0.0001 \nepochs = 30\nval_percent = 0.2\nn_classes = 39\nweight_decay = 0.0001 \nhidden_dim = 1024\noutput_dim = n_classes\nhidden_num = 12\n\nneed_ckpt = True",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-24T02:51:49.600560Z",
     "iopub.execute_input": "2022-11-24T02:51:49.601087Z",
     "iopub.status.idle": "2022-11-24T02:51:49.609417Z",
     "shell.execute_reply.started": "2022-11-24T02:51:49.601043Z",
     "shell.execute_reply": "2022-11-24T02:51:49.607982Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Load data",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "train_data = np.load(train_data_path)\ntrain_label = np.load(train_label_path)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-23T12:43:17.010261Z",
     "iopub.execute_input": "2022-11-23T12:43:17.010882Z",
     "iopub.status.idle": "2022-11-23T12:43:20.774443Z",
     "shell.execute_reply.started": "2022-11-23T12:43:17.010743Z",
     "shell.execute_reply": "2022-11-23T12:43:20.772970Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "print(\"train data size: \", train_data.shape)\nprint(\"train label size: \", train_label.shape)\n\nn_train_tot = train_data.shape[0]\nn_val = int(n_train_tot * val_percent)\nn_train = n_train_tot - n_val\n\ntrain_x = train_data[:n_train]\ntrain_y = train_label[:n_train]\nval_x = train_data[n_train:]\nval_y = train_label[n_train:]\n# print(\"train set size: \", train_x.shape, train_y.shape)\n# print(\"validate set size: \", val_x.shape, val_y.shape)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-23T12:43:20.777337Z",
     "iopub.execute_input": "2022-11-23T12:43:20.777761Z",
     "iopub.status.idle": "2022-11-23T12:43:20.789222Z",
     "shell.execute_reply.started": "2022-11-23T12:43:20.777722Z",
     "shell.execute_reply": "2022-11-23T12:43:20.786784Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Define the dataset",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class TimitDataset(nn.Module):\n    def __init__(self, X, Y = None):\n        super().__init__()\n        self.X = torch.from_numpy(X)\n        if Y is not None:\n            self.Y = torch.LongTensor(Y.astype(np.int64))\n        else:\n            self.Y = None\n    \n    def __getitem__(self, index):\n        if self.Y is None:\n            return self.X[index]\n        else:\n            return self.X[index], self.Y[index]\n        \n    def __len__(self):\n        return self.X.shape[0]",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-24T02:51:52.615482Z",
     "iopub.execute_input": "2022-11-24T02:51:52.615968Z",
     "iopub.status.idle": "2022-11-24T02:51:52.626167Z",
     "shell.execute_reply.started": "2022-11-24T02:51:52.615927Z",
     "shell.execute_reply": "2022-11-24T02:51:52.624488Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "train_set = TimitDataset(train_x, train_y) \nval_set = TimitDataset(val_x, val_y)\n\nprint(\"train set size is:\", len(train_set))\nprint(\"validate set size is:\", len(val_set))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-23T12:43:20.804445Z",
     "iopub.execute_input": "2022-11-23T12:43:20.804840Z",
     "iopub.status.idle": "2022-11-23T12:43:21.175750Z",
     "shell.execute_reply.started": "2022-11-23T12:43:20.804806Z",
     "shell.execute_reply": "2022-11-23T12:43:21.174157Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Do some GC",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import gc\n\ndel train_data, train_label, train_x, train_y, val_x, val_y\ngc.collect()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-23T12:43:21.177354Z",
     "iopub.execute_input": "2022-11-23T12:43:21.177846Z",
     "iopub.status.idle": "2022-11-23T12:43:21.376115Z",
     "shell.execute_reply.started": "2022-11-23T12:43:21.177805Z",
     "shell.execute_reply": "2022-11-23T12:43:21.374785Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Define the model",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "class BasicBlock(nn.Module):\n    def __init__(self, in_dim, out_dim):\n        super().__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(in_dim, out_dim),\n            nn.BatchNorm1d(out_dim),\n            nn.ReLU(),\n            nn.Dropout()\n        )\n        \n    def forward(self, x):\n        return self.layers(x)\n\nclass TimitModel(nn.Module):\n    def __init__(self, out_dim: int):\n        super().__init__()\n        \n        self.lstm = nn.GRU(39, 256, 2, batch_first=True, dropout=0.25)\n        self.out = nn.Sequential(\n            BasicBlock(11*256, 1024),\n            nn.Linear(1024, out_dim),\n            nn.Softmax(dim=1),\n        )\n        \n    def forward(self, x):\n        x = x.view(-1, 11, 39)\n        x, _ = self.lstm(x)\n        x = x.contiguous().view(x.size(0), -1)\n        x = self.out(x)\n        return x",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-24T03:30:45.808397Z",
     "iopub.execute_input": "2022-11-24T03:30:45.808886Z",
     "iopub.status.idle": "2022-11-24T03:30:45.823930Z",
     "shell.execute_reply.started": "2022-11-24T03:30:45.808847Z",
     "shell.execute_reply": "2022-11-24T03:30:45.822227Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Training",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def save_ckpt(model: nn.Module, epoch:int, loss:float):\n    print('save ckpt, epoch = {}, loss = {}'.format(epoch, loss))\n    torch.save(model.state_dict(), 'ckpt_epoch_{}_loss_{}.pth'.format(epoch, loss))",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-23T12:43:21.394423Z",
     "iopub.execute_input": "2022-11-23T12:43:21.394835Z",
     "iopub.status.idle": "2022-11-23T12:43:21.407560Z",
     "shell.execute_reply.started": "2022-11-23T12:43:21.394800Z",
     "shell.execute_reply": "2022-11-23T12:43:21.406241Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Fix random seeds for reproducibility",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# fix random seed\ndef same_seeds(seed):\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)  \n    np.random.seed(seed)  \n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True\n    \nsame_seeds(0)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-23T12:43:21.410751Z",
     "iopub.execute_input": "2022-11-23T12:43:21.411316Z",
     "iopub.status.idle": "2022-11-23T12:43:21.421602Z",
     "shell.execute_reply.started": "2022-11-23T12:43:21.411264Z",
     "shell.execute_reply": "2022-11-23T12:43:21.420716Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = TimitModel(output_dim)\nprint(model)\n\nmodel.to(device)\n\n# load pth\nif os.path.exists(\"best_model.pth\"):\n    model.load_state_dict(torch.load('best_model.pth', map_location=device))\n\nopt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, int(1e10), eta_min=1e-5)\ncriterion = nn.CrossEntropyLoss()\n\ntrain_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(dataset=val_set, batch_size=batch_size, shuffle=False)\n\n# read loss\nbest_loss = float('inf')\nif os.path.exists('best_loss.txt'):\n    with open('best_loss.txt', mode='r') as f:\n        best_loss = float(f.readline())\n        print(\"read best loss:\", best_loss)\n\nfor epoch in range(epochs):\n    model.train()\n    if epoch % 50 == 0:\n        print('trainning...epoch = %d' % epoch)\n    train_tot_loss = 0\n    train_tot_acc = 0\n    for x, y in train_loader:\n        opt.zero_grad()\n\n        x = x.to(device=device, dtype=torch.float32)\n        y_true = y.to(device=device)\n        y_pred = model(x)\n        # compute loss\n        loss = criterion(y_pred, y_true)\n\n        train_tot_loss += loss.item()\n        _, pred_classes = torch.max(y_pred, 1)\n        train_tot_acc += (pred_classes.cpu() == y_true.cpu()).sum().item()\n        # update\n        loss.backward()\n        opt.step()\n        scheduler.step()\n              \n    print('Avg Loss/train:', train_tot_loss / len(train_loader))\n    print('Avg Acc/train:', train_tot_acc / len(train_set))\n        \n    if len(val_loader) > 0:\n        val_tot_loss = 0\n        with torch.no_grad():\n            for x, y in val_loader:\n                x = x.to(device=device, dtype=torch.float32)\n                y_true = y.to(device=device)\n                y_pred = model(x)\n                val_tot_loss += criterion(y_pred, y_true).item()\n                \n        val_loss = val_tot_loss / len(val_loader)        \n        if val_loss < best_loss:\n            print('Avg Loss/Validate:', val_loss)\n            with open('best_loss.txt', mode='w') as f:\n                f.write(str(val_loss))\n            best_loss = val_loss\n            torch.save(model.state_dict(), 'best_model.pth')\n    \n    if need_ckpt and epoch % 5 == 0:\n        save_ckpt(model, epoch, train_tot_loss / len(train_loader))\n    ",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-23T12:43:21.422975Z",
     "iopub.execute_input": "2022-11-23T12:43:21.423886Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "test_model = TimitModel(output_dim)\ntest_model.load_state_dict(torch.load('best_model.pth', map_location=device))\ntest_model.to(device)\ntest_model.eval()\n\ntest_data = np.load(test_data_path)\nprint(\"test data size:\", test_data.shape)\ntest_set = TimitDataset(test_data)\ntest_loader = DataLoader(dataset=test_set, batch_size=1, shuffle=False)",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-24T02:51:55.848112Z",
     "iopub.execute_input": "2022-11-24T02:51:55.848756Z",
     "iopub.status.idle": "2022-11-24T02:52:10.391093Z",
     "shell.execute_reply.started": "2022-11-24T02:51:55.848712Z",
     "shell.execute_reply": "2022-11-24T02:52:10.389342Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Testing",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "classes = []\nwith torch.no_grad():\n    for x in test_loader:\n        x = x.to(device=device, dtype=torch.float32)\n        y_pred = test_model(x)\n        _, pred_classes = torch.max(y_pred, 1)\n        classes.append(pred_classes[0].item())",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-24T02:52:46.150502Z",
     "iopub.execute_input": "2022-11-24T02:52:46.150974Z",
     "iopub.status.idle": "2022-11-24T03:08:19.605071Z",
     "shell.execute_reply.started": "2022-11-24T02:52:46.150935Z",
     "shell.execute_reply": "2022-11-24T03:08:19.603934Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import pandas as pd\ndf = pd.DataFrame({'Class': classes})\ndf.index.name = 'Id'\ndf.to_csv('submission.csv')",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-24T03:09:24.411342Z",
     "iopub.execute_input": "2022-11-24T03:09:24.411775Z",
     "iopub.status.idle": "2022-11-24T03:09:25.092631Z",
     "shell.execute_reply.started": "2022-11-24T03:09:24.411739Z",
     "shell.execute_reply": "2022-11-24T03:09:25.091258Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}